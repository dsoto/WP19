{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes the data from the power meter to determine the fraction of the time that power is available on five microgrids in the Lake Sentani area.\n",
    "\n",
    "# Data cleaning\n",
    "\n",
    "TODO: decide if the Data Cleaning code should be published.\n",
    "\n",
    "The raw data files are in Microsoft Excel format and are created by the metering software.\n",
    "\n",
    "Issues:\n",
    "- the excel files contain analysis graphs in the header\n",
    "- data is reported in reverse chronological order with latest data first in the file\n",
    "- when communication is lost, there is a \"communication lost\" string inserted into the power reading\n",
    "- there are \"power down\" and \"power up\" readings inserted into the kWh export power reading when the generator turns off\n",
    "- I have observed non-monotonicity in data that should be monotonic\n",
    "\n",
    "These files need to be turned into well-behaved CSV files.\n",
    "Ideally, this would be completely scripted using libraries for reading Excel files and exporting CSV files.\n",
    "However, the files as created by the metering software cannot be read by some python Excel libraries.\n",
    "I assume this is because the Excel files deviate from the expected format.\n",
    "\n",
    "Each of the months of data are read in as Excel files, cleaned of communication messages, and converted to a list of data frames.\n",
    "These data frames are then concatenated, sorted by the date time index and saved to disk as a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajau.csv\n",
      "Diesel_Data/raw_data/4. April/Data_Logs AJAU April 22 - 30.xls\n",
      "WARNING *** file size (3625288) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/5. May/Data_Logs AJAU MAY.xls\n",
      "Diesel_Data/raw_data/6. June/Data_Logs AJAU June.xls\n",
      "WARNING *** file size (13147260) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/7. July/Data_Logs AJAU July.xls\n",
      "WARNING *** file size (13790853) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/8. Agustus/Data_Logs Ajau Agustus.xls\n",
      "WARNING *** file size (12314552) not 512 + multiple of sector size (512)\n",
      "asei.csv\n",
      "Diesel_Data/raw_data/4. April/Data_Logs ASEI April 22 - 30.xls\n",
      "WARNING *** file size (3531439) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/5. May/Data_Logs ASEI MAY.xls\n",
      "Diesel_Data/raw_data/6. June/Data_Logs ASEI June.xls\n",
      "WARNING *** file size (12805177) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/7. July/Data_Logs ASEI July.xls\n",
      "atamali.csv\n",
      "Diesel_Data/raw_data/4. April/Data_Logs ATAMALI 24 - 30.xls\n",
      "WARNING *** file size (854876) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/5. May/Data_Logs ATAMALI MAY.xls\n",
      "WARNING *** file size (3493755) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/6. June/Data_Logs ATAMALI June.xls\n",
      "WARNING *** file size (1531924) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/7. July/Data_Logs ATAMALI July.xls\n",
      "WARNING *** file size (2705463) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/8. Agustus/Data_Logs Atamali Agustus.xls\n",
      "WARNING *** file size (2439980) not 512 + multiple of sector size (512)\n",
      "ayapo.csv\n",
      "Diesel_Data/raw_data/4. April/Data_Logs AYAPO April 22 - 30.xls\n",
      "WARNING *** file size (1049728) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/5. May/Data_Logs AYAPO MAY.xls\n",
      "Diesel_Data/raw_data/6. June/Data_Logs AYAPO June.xls\n",
      "WARNING *** file size (3296098) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/7. July/Data_Logs AYAPO July.xls\n",
      "WARNING *** file size (4025791) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/8. Agustus/Data_Logs Ayapo Agustus.xls\n",
      "WARNING *** file size (2858944) not 512 + multiple of sector size (512)\n",
      "kensio.csv\n",
      "Diesel_Data/raw_data/5. May/Data_Logs KENSIO MAY.xls\n",
      "WARNING *** file size (691081) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/6. June/Data_Logs KENSIO June.xls\n",
      "WARNING *** file size (988130) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/7. July/Data_Logs KENSIO July.xls\n",
      "WARNING *** file size (1265344) not 512 + multiple of sector size (512)\n",
      "Diesel_Data/raw_data/8. Agustus/Data_Logs Kensio Agustus.xls\n",
      "WARNING *** file size (1385249) not 512 + multiple of sector size (512)\n"
     ]
    }
   ],
   "source": [
    "# TODO: check for non-numeric entries\n",
    "# TODO: maybe report how many events removed?\n",
    "# TODO: look out for rows with null data\n",
    "# TODO: set permissions to read-only for the output CSV files\n",
    "\n",
    "import pandas as pd\n",
    "import WP19_analysis\n",
    "\n",
    "prefix = 'Diesel_Data/raw_data/'\n",
    "\n",
    "for rfd in WP19_analysis.raw_file_data:\n",
    "    energy_dfs = []\n",
    "    message_dfs = []\n",
    "    files = rfd['files']\n",
    "    skiprows = rfd['skiprows']\n",
    "    output_file = rfd['output_file']\n",
    "    print(output_file)\n",
    "    for f,sr in zip(files, skiprows):\n",
    "        # convert excel file to temporary csv file on disk\n",
    "        print(prefix + f)\n",
    "        excel_data = pd.read_excel(prefix + f, skiprows=sr)\n",
    "        assert 'Timestamp' in excel_data.columns, 'check your skiprows, header not found'\n",
    "        excel_data.to_csv('temp.csv')\n",
    "\n",
    "        # remove messages from csv file string object\n",
    "        temp_csv = open('temp.csv')\n",
    "        file_string = ''\n",
    "        messages = 'date,index,message\\n'\n",
    "        omit_strings = ['Power Up', 'Communication Lost', 'Power Down', ',,,,,,,,,,,']\n",
    "        for line in temp_csv.readlines():\n",
    "            if not any(omit in line for omit in omit_strings):\n",
    "                file_string += line\n",
    "            else:\n",
    "                fields = line.split(',')\n",
    "                #import pdb;pdb.set_trace()\n",
    "                messages += ','.join((fields[1], fields[0], fields[3]))\n",
    "                messages += '\\n'\n",
    "\n",
    "\n",
    "        # read in string object to dataframe, sort and add to dataframe list\n",
    "        import io\n",
    "        energy_data = pd.read_csv(io.StringIO(file_string),\n",
    "                              index_col=1, \n",
    "                              parse_dates=[1], \n",
    "                              thousands=',')\n",
    "        energy_data = energy_data.sort_index()\n",
    "        energy_dfs.append(energy_data)\n",
    "        \n",
    "        message_data = pd.read_csv(io.StringIO(messages),\n",
    "                              index_col=0, \n",
    "                              parse_dates=[0])\n",
    "        message_data = message_data.sort_index()\n",
    "        message_dfs.append(message_data)\n",
    "\n",
    "\n",
    "    pd.concat(energy_dfs).to_csv(output_file)\n",
    "    pd.concat(message_dfs).to_csv(rfd['village_name'] + '-messages.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that these have been processed, we can validate the files.\n",
    "\n",
    "- TODO: what is the best way to import my validation code?  install a specific version or copy the code in repo?\n",
    "- TODO: is the energy field monotonic?\n",
    "- TODO: does the energy field have non-numeric entries?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the MD5 hashes created on 19 June 2017 for the energy data files.\n",
    "Subsequent runs of the cleaning code above don't change the hashes.\n",
    "\n",
    "    MD5 (ajau.csv) = bd95712a4ce565d18514f3360b9cd9d0\n",
    "    MD5 (asei.csv) = 9c0241dc30b1016252efd7d2dfdc6acf\n",
    "    MD5 (atamali.csv) = 8987744da6d1e3b85f26c304e7d3b9e5\n",
    "    MD5 (ayapo.csv) = 145ebb04af288701b488563f9d69f8c0\n",
    "    MD5 (kensio.csv) = bb2f8d983550c8354365381f32972ff9\n",
    "    \n",
    "These are the MD5 hashes created on 21 June 2017 for the message files.\n",
    "\n",
    "    MD5 (ajau-messages.csv) = 641f05537199c2b0f018d9c8466ab0e1\n",
    "    MD5 (asei-messages.csv) = 307e1324a6be53113ae75f3403653df5\n",
    "    MD5 (atamali-messages.csv) = 2ebe8dd3556e9c1cba70c3a3e5c51023\n",
    "    MD5 (ayapo-messages.csv) = 0fecace21d41da147f5e3fb973f8c5db\n",
    "    MD5 (kensio-messages.csv) = a124f6a37949ecd1a50bb593d0880b03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD5 (ajau.csv) = bd95712a4ce565d18514f3360b9cd9d0\n",
      "MD5 (asei.csv) = 9c0241dc30b1016252efd7d2dfdc6acf\n",
      "MD5 (atamali.csv) = 8987744da6d1e3b85f26c304e7d3b9e5\n",
      "MD5 (ayapo.csv) = 145ebb04af288701b488563f9d69f8c0\n",
      "MD5 (kensio.csv) = bb2f8d983550c8354365381f32972ff9\n"
     ]
    }
   ],
   "source": [
    "# this uses the jupyter notebook syntax to make system calls\n",
    "for rfd in WP19_analysis.raw_file_data:\n",
    "    md5file = rfd['output_file']\n",
    "    !md5 {md5file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD5 (ajau-messages.csv) = 641f05537199c2b0f018d9c8466ab0e1\n",
      "MD5 (asei-messages.csv) = 307e1324a6be53113ae75f3403653df5\n",
      "MD5 (atamali-messages.csv) = 2ebe8dd3556e9c1cba70c3a3e5c51023\n",
      "MD5 (ayapo-messages.csv) = 0fecace21d41da147f5e3fb973f8c5db\n",
      "MD5 (kensio-messages.csv) = a124f6a37949ecd1a50bb593d0880b03\n"
     ]
    }
   ],
   "source": [
    "for rfd in WP19_analysis.raw_file_data:\n",
    "    md5file = rfd['village_name'] + '-messages.csv'\n",
    "    !md5 {md5file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
